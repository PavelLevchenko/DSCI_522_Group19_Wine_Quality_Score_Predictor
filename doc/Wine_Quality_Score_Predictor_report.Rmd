---
title: "Predicting wine quality score from various characteristics"
author: "Group 19 - Kingslin Lv, Manju Neervaram Abhinandana Kumar, Zack Tang, Paval Levchenko"
bibliography: references_wine_score_predictor.bib
output: 
  md_document: 
    toc: true
  github_document:
    toc: true
  html_document: 
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)

cv_scores_df <- read_csv("../results/cv_scores_for_alternative_methods.csv")
final_results_df <- read_csv("../results/final_results.csv")
```

# Summary

In this project we aim to predict the wine quality scores ranging from 0 to 10 based on physicochemical properties of wines sensory tests. To answer this predictive question, we decided to build a regression model. Through our exploratory data analysis we analyzed the distribution of each feature and correlation between features and the target. Followed by the cross-validation process based on feature input, we concluded that the Random Forest Regressor delivers a much higher training score, but there was a clear problem of overfitting. We further conducted feature selection and hyperparameter optimization in an attempt to reduce the score gap between train and test scores. We were able to drop a number of features but maintain a relatively similar score through this process. Unfortunately, the test score with our best hyperparameters was only around `r final_results_df[[6,2]]`, which is fairly acceptable. Next, we can potentially improve our model prediction score by using a larger dataset with more features or build a higher score model with its best hyperparameters.

# Introduction

The wine industry shows a recent extensive growth and the industry experts are using product quality certifications to promote their products[@orth2001quality]. This is a time-consuming process and requires the assessment given by human experts, which makes this process very expensive. The wine market would be of interest if the human quality of tasting can be related to wine's chemical properties so that quality assessment processes are more controlled. This project aims to build a machine learning model for purpose of predicting the wine quality score based on each of its specific chemical properties. This task will likely require a lot of domain knowledge and according to a paper published by Dr. P. Cortez, Dr. A. Cerdeira, Dr. F. Almeida, Dr. T. Matos and Dr. J. Reis they were able to demonstrate the data mining approach could have a promising result compared to alternative neural network methods [@CORTEZ2009547].

Our model is useful to support wine tasting evaluations. Quality evaluation is a part of wine certification process and can be used to improve wine making or spot premium wines for a more proper price according to customer taste preferences. Additionally, using human taste as a sensory measurement for wine quality could be quite unreliable [@de2017sensory]. We are also interested in exploring to what extent the score depends on other sensory information such as color of wine. Potentially, human brain could be processing taste and visual information differently rather than taste only. Thus, we are not expecting to obtain a really high test score to our machine learning model.

# Methods

## Data

The dataset used in this project is retrieved from the University of California Irvine (UCI) machine learning repository [@Dua2019] and was collected by Paulo Cortez, University of Minho, GuimarÃ£es, Portugal and A. Cerdeira, F. Almeida, T. Matos with help from J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal in 2009. This dataset contains the results of various physiochemical test, including scoring for properties like fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, and alcohol (11 features), which were preformed on white "Vinho Verde" wine samples from Northern Portugal. The data used in our analysis can be found [here](https://archive.ics.uci.edu/ml/datasets/wine+quality). Additionally, we add one more feature by concatenating white and red wine data, and so there is a binary feature; we think potentially human's perception of wine type may affect the independent scoring on the wine quality, and so we added a binary feature to account for this factor. Thus, there are 5197 instances and 12 features upon we combined both red and white wine data. There are not misssing data in this dataset, which is demonstrated with summary in the "results" folder. 

One of drawback of our raw data is that there is no additional feature or specific branding of each wine available in the dataset for privacy purposes. Each row in the dataset represents a single wine which was tested and scored based on human sensory data.

## Analysis

As the first step towards building the model to answer the predictive question proposed above we split the data into train and test data set at 80% and 20% level. We performed our exploratory data analysis on the training data frame. Firstly, we plotted the distribution of the quality scores for each wine (Figure 1). Despite the quality scoring being performed a scale from 1-10 only values in the range of 3-9 were observed, and it can be seen that our data is significantly imbalanced, with 6 being the most common score observed across all testing while scores such as 3 and 9 were rarely seen.

```{r fig_1, echo=FALSE, fig.cap="Figure 1. Distribution of quality scores", out.width = '30%'}
knitr::include_graphics("../results/quality_dist.png")
```

After taking a look at the distributions of our 11 numerical features, and we realized all attributes have outliers with extreme value. We will have to scale numerical features in order to reduce skewness at the process of building the model. Also, there is a class imbalance issues as revealed from the distribution plot.

```{r fig_2, echo=FALSE, fig.cap="Figure 2. Data distribution of numeric features in training datasets.", out.width = '100%'}
knitr::include_graphics("../results/repeat_plots.png")
```

By exploring the features correlation matrix Figure 3, we identified that some features are highly correlated, and we will drop some redundant features in the process of feature selection. By the below correlation matrix, volatile.acidity, sulphates and alcohol are the attributes most correlated with quality of wine. Thus, these 3 attributes are most relevant. We might drop some features that have smaller correlations. We will further identify this through our model establishment process.

```{r fig_3, echo=FALSE, fig.cap="Figure 3. Quality distribution of wines in the training and test datasets.", out.width = '60%'}
knitr::include_graphics("../results/cor_plot.png")
```

Furthemore, the data was processed through the pandas package; EDA was plotted using python the library Altair and the preliminary insights on EDA was using the pandas-profiling package [@reback2020pandas] [@pandasprofiling2019]. This report was compiled using an R document file with scripts running via the docopt package [@R], [@docopt]. Tables were stored via csv files and displayed using knitr's kable function [@knitr], [@rmarkdown]. After tuning the model, we will use test data set to do the final check of the accuracy. If the result is not satisfactory, we will make further adjustments based on the new issue found.

# Results & Discussion

After we decided to approach our problem as regression issue, we chose four typical regression supervised machine learning models `Ridge`, `OneVsRestClassifier(LogisticRegression)`, `SVR`, and `RandomForestRegressor`[@Python], [@scikit-learn]. To better understand the performance of our selected models, we decided to evaluate negative mean squared error, negative root mean squared error, negative mean absolute error, r squared and MAPE scores given this is a regression issue with multiple feature coefficients. The cross-validation scores for each model is summarized in the Table 1. We discovered that `RandomForestRegressor` returned the highest cross-validation score, and so next we decided to further tune the `RandomForestRegressor` model via feature selection and hyper-parameter optimization to address the issue of overfitting.

Moreover there is an issue of imbalanced dataset. This bias in the training dataset can influence many machine learning algorithms, leading some to ignore the minority class entirely. This is a problem as it is typically the minority class on which predictions are most important. One approach to addressing the problem of class imbalance is to randomly resample the training dataset, and thus we determined `RandomOverSampler(sampling_strategy="minority")`to address this issue. 

Lastly, we applied Recursive Features Elimination (RFE) for preliminary feature selections, and limited the number of features as 10 in order to make the model more efficient. Through this algorithm we determined to drop `type` and `density` features, and we are able to achieve very similar scores with lesser features as displayed in the Table 1. This process simplifies our model and it's cost-efficient for future data collection.

```{r table_1, echo=FALSE, out.width = '60%'}
kable(cv_scores_df,
      caption="Table 1. Table of cross-validation results for each tested model")
```

Finally, we conducted hyperparameter optimization as `RandomForestRegressor` encountered severe overfitting issue. The best hyperparameters we obtained from the algorithm are `max_depth` at `r final_results_df[[1,2]]`, `max_leaf_nodes` at `r final_results_df[[2,2]]`, and `n_estimators`at `r final_results_df[[3,2]]` The best cross-validation score is `r final_results_df[[4,2]]` using the best hyperparameter. The score for test data set is `r final_results_df[[6,2]]` upon tunning hyper-parameters; however, as we discovered above, the train score is `r final_results_df[[5,2]]` as displayed in the Table 2, which indicates that we still have overfitting issue for the `RandomForestRegressor` model.

```{r table_2, echo=FALSE, out.width = '60%'}
kable(final_results_df,
       caption="Table 2. Tuned (+ reduced features) RandomForestRegressor model test results.")
```

# Limitations & Future

The wine classification is a challenging task as it relies on sensory analysis performed by human tasters. These evaluations are based on the experience and knowledge of experts which are prone to be subjective factors. One of main limitation here is that the dataset is imbalanced. The majority of quality scores were 5 and 6. Another limitation is that the dataset has only 12 features with one of binary feature that seems not to add any values to our model. We could also potentially find a larger dataset (i.e.with wine from different parts of the world) or with more features since the one we are currently working with has a limited number of features (i.e. lack of type of grape used in the wine) due for the sake of privacy protection.

# References
