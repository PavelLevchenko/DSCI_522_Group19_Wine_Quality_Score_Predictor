{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c77f90-6f9b-49e0-a67e-c684fa30d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score, \n",
    "    auc\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e67f4c5-f3da-4eb3-9aab-64bd2b268a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_df = pd.read_csv(\"../data/raw/winequality-white.csv\", sep=\";\")\n",
    "red_df = pd.read_csv(\"../data/raw/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "red_df['type']='red wine'\n",
    "white_df['type']='white wine'\n",
    "wine = pd.concat([red_df,white_df]).reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "348c881b-1424-4381-9b54-18e8211b8dec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddaa3243-1b87-4533-9a9f-9b2225e3a5bf",
   "metadata": {},
   "source": [
    "We combined both csv files together and created a \"type\" column to see whether the type of the wine will affect the judgement of the quality. Because sometimes, human's perception of wine type may affect the independent scoring on the wine quality, so that's why we added a binary feature to account for this factor. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9018bcf2-4320-459f-8f4b-579a11c851c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a2dc65-6a14-438c-949c-caefdfb9ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(wine, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474d866f-ec50-4ce2-b0f1-6c46543718d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"quality\"])\n",
    "X_test = test_df.drop(columns=[\"quality\"])\n",
    "\n",
    "y_train = train_df[\"quality\"]\n",
    "y_test = test_df[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4029b7f7-b303-4c32-adbb-33f698248a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = X_train.select_dtypes(include=[np.number]).columns.values.tolist()\n",
    "binary_feats = [\"type\"]\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "binary_transformer = make_pipeline(OneHotEncoder(drop=\"if_binary\", dtype=int))\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_feats),\n",
    "    (binary_transformer, binary_feats)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "274d8755-91d4-4815-a5f9-10db13adf20c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e4d9a8-61f1-4292-85b3-76a361a2460f",
   "metadata": {},
   "source": [
    "In our data file, we only have numerical features originally; however we need to scale those number before we feed them in the model. And we engineered a binary feature (\"type\"), we used `OneHotEncoder` with `drop=\"if_binary\"` argument to form the transformer. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c89bba31-ec7a-4c0c-b6ef-740683c1fe65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badf7f5b-f0fb-431f-b7d2-78d9070f6011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.552156</td>\n",
       "      <td>-0.537847</td>\n",
       "      <td>-0.616843</td>\n",
       "      <td>-0.849603</td>\n",
       "      <td>-0.256654</td>\n",
       "      <td>-0.599698</td>\n",
       "      <td>-0.688718</td>\n",
       "      <td>-1.550251</td>\n",
       "      <td>0.637496</td>\n",
       "      <td>0.602356</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.551023</td>\n",
       "      <td>-0.903607</td>\n",
       "      <td>-0.274431</td>\n",
       "      <td>-0.849603</td>\n",
       "      <td>-0.285082</td>\n",
       "      <td>-0.487984</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>-1.427678</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.134424</td>\n",
       "      <td>1.005574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065059</td>\n",
       "      <td>-0.720727</td>\n",
       "      <td>0.547359</td>\n",
       "      <td>1.949924</td>\n",
       "      <td>-0.398798</td>\n",
       "      <td>0.768801</td>\n",
       "      <td>0.234073</td>\n",
       "      <td>1.692956</td>\n",
       "      <td>0.887242</td>\n",
       "      <td>-0.804224</td>\n",
       "      <td>-1.161136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.165971</td>\n",
       "      <td>-0.598807</td>\n",
       "      <td>0.273429</td>\n",
       "      <td>-0.556020</td>\n",
       "      <td>-0.626230</td>\n",
       "      <td>-0.487984</td>\n",
       "      <td>-0.073524</td>\n",
       "      <td>-1.553564</td>\n",
       "      <td>-0.174178</td>\n",
       "      <td>-1.005164</td>\n",
       "      <td>1.755589</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011951</td>\n",
       "      <td>-0.598807</td>\n",
       "      <td>-0.137466</td>\n",
       "      <td>-0.807663</td>\n",
       "      <td>-0.228225</td>\n",
       "      <td>-0.208698</td>\n",
       "      <td>0.260438</td>\n",
       "      <td>-0.460348</td>\n",
       "      <td>0.200441</td>\n",
       "      <td>-0.536304</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>-0.319992</td>\n",
       "      <td>0.681350</td>\n",
       "      <td>-0.274431</td>\n",
       "      <td>4.319561</td>\n",
       "      <td>-0.711516</td>\n",
       "      <td>-0.208698</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>2.736480</td>\n",
       "      <td>-0.985853</td>\n",
       "      <td>-0.737244</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0.758151</td>\n",
       "      <td>-0.476888</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>-0.597961</td>\n",
       "      <td>-0.086080</td>\n",
       "      <td>-1.102412</td>\n",
       "      <td>-0.794180</td>\n",
       "      <td>-0.221828</td>\n",
       "      <td>-2.047274</td>\n",
       "      <td>-0.268384</td>\n",
       "      <td>-0.827796</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.859063</td>\n",
       "      <td>1.534788</td>\n",
       "      <td>-2.123458</td>\n",
       "      <td>-0.702812</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>-1.437555</td>\n",
       "      <td>-1.813644</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>1.886227</td>\n",
       "      <td>0.200476</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0.604131</td>\n",
       "      <td>-0.720727</td>\n",
       "      <td>-0.274431</td>\n",
       "      <td>1.792647</td>\n",
       "      <td>-0.086080</td>\n",
       "      <td>2.919299</td>\n",
       "      <td>1.420518</td>\n",
       "      <td>1.129784</td>\n",
       "      <td>-0.486361</td>\n",
       "      <td>-0.536304</td>\n",
       "      <td>-0.577791</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>0.296090</td>\n",
       "      <td>-0.842647</td>\n",
       "      <td>-0.137466</td>\n",
       "      <td>1.834587</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>1.243586</td>\n",
       "      <td>1.692961</td>\n",
       "      <td>1.427934</td>\n",
       "      <td>-0.486361</td>\n",
       "      <td>-0.469324</td>\n",
       "      <td>-1.327806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0         -1.552156         -0.537847    -0.616843       -0.849603  -0.256654   \n",
       "1         -0.551023         -0.903607    -0.274431       -0.849603  -0.285082   \n",
       "2          0.065059         -0.720727     0.547359        1.949924  -0.398798   \n",
       "3         -0.165971         -0.598807     0.273429       -0.556020  -0.626230   \n",
       "4         -0.011951         -0.598807    -0.137466       -0.807663  -0.228225   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "5192      -0.319992          0.681350    -0.274431        4.319561  -0.711516   \n",
       "5193       0.758151         -0.476888     0.067982       -0.597961  -0.086080   \n",
       "5194      -0.859063          1.534788    -2.123458       -0.702812  -0.000793   \n",
       "5195       0.604131         -0.720727    -0.274431        1.792647  -0.086080   \n",
       "5196       0.296090         -0.842647    -0.137466        1.834587  -0.000793   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0               -0.599698             -0.688718 -1.550251  0.637496   \n",
       "1               -0.487984             -0.460217 -1.427678 -0.236615   \n",
       "2                0.768801              0.234073  1.692956  0.887242   \n",
       "3               -0.487984             -0.073524 -1.553564 -0.174178   \n",
       "4               -0.208698              0.260438 -0.460348  0.200441   \n",
       "...                   ...                   ...       ...       ...   \n",
       "5192            -0.208698              0.102245  2.736480 -0.985853   \n",
       "5193            -1.102412             -0.794180 -0.221828 -2.047274   \n",
       "5194            -1.437555             -1.813644  0.010066  1.886227   \n",
       "5195             2.919299              1.420518  1.129784 -0.486361   \n",
       "5196             1.243586              1.692961  1.427934 -0.486361   \n",
       "\n",
       "      sulphates   alcohol  type  \n",
       "0      0.602356  0.755569   1.0  \n",
       "1     -0.134424  1.005574   1.0  \n",
       "2     -0.804224 -1.161136   1.0  \n",
       "3     -1.005164  1.755589   1.0  \n",
       "4     -0.536304  0.005554   1.0  \n",
       "...         ...       ...   ...  \n",
       "5192  -0.737244  0.088889   1.0  \n",
       "5193  -0.268384 -0.827796   1.0  \n",
       "5194   0.200476  0.755569   0.0  \n",
       "5195  -0.536304 -0.577791   1.0  \n",
       "5196  -0.469324 -1.327806   1.0  \n",
       "\n",
       "[5197 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = numeric_feats + binary_feats\n",
    "pd.DataFrame(preprocessor.fit_transform(X_train, y_train), columns = column_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d031f411-f530-4993-9f16-acf76b8c76c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78eaf113-7a0f-41e3-b8cc-8294be97ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported from DSCI 573 Lecture Notes from UBC\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e82be241-e31f-4d54-9bd6-94d761c78bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported from DSCI 573 Lecture Notes from UBC\n",
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(max_iter=2000),\n",
    "    \"SVR\": SVR(),\n",
    "    \"OneVsRest\":OneVsRestClassifier(LogisticRegression()),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=123)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbcda176-083d-46b9-85a6-c59e3c8f17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2435e9c4-bd91-4bf1-9e1b-a8309a328e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVR</th>\n",
       "      <th>OneVsRest</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.023 (+/- 0.004)</td>\n",
       "      <td>1.073 (+/- 0.064)</td>\n",
       "      <td>0.143 (+/- 0.009)</td>\n",
       "      <td>1.616 (+/- 0.016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.350 (+/- 0.007)</td>\n",
       "      <td>0.005 (+/- 0.000)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <td>-1.093 (+/- 0.097)</td>\n",
       "      <td>-0.503 (+/- 0.018)</td>\n",
       "      <td>-0.880 (+/- 0.072)</td>\n",
       "      <td>-0.402 (+/- 0.030)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <td>-1.071 (+/- 0.048)</td>\n",
       "      <td>-0.427 (+/- 0.013)</td>\n",
       "      <td>-0.835 (+/- 0.046)</td>\n",
       "      <td>-0.057 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <td>-1.044 (+/- 0.047)</td>\n",
       "      <td>-0.709 (+/- 0.013)</td>\n",
       "      <td>-0.938 (+/- 0.039)</td>\n",
       "      <td>-0.634 (+/- 0.024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <td>-1.035 (+/- 0.023)</td>\n",
       "      <td>-0.654 (+/- 0.010)</td>\n",
       "      <td>-0.913 (+/- 0.025)</td>\n",
       "      <td>-0.239 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <td>-0.806 (+/- 0.025)</td>\n",
       "      <td>-0.531 (+/- 0.009)</td>\n",
       "      <td>-0.590 (+/- 0.017)</td>\n",
       "      <td>-0.457 (+/- 0.015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <td>-0.802 (+/- 0.022)</td>\n",
       "      <td>-0.474 (+/- 0.004)</td>\n",
       "      <td>-0.571 (+/- 0.013)</td>\n",
       "      <td>-0.170 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-0.436 (+/- 0.141)</td>\n",
       "      <td>0.339 (+/- 0.019)</td>\n",
       "      <td>-0.154 (+/- 0.091)</td>\n",
       "      <td>0.473 (+/- 0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>-0.405 (+/- 0.063)</td>\n",
       "      <td>0.440 (+/- 0.016)</td>\n",
       "      <td>-0.095 (+/- 0.061)</td>\n",
       "      <td>0.925 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <td>-14.606 (+/- 0.662)</td>\n",
       "      <td>-9.431 (+/- 0.282)</td>\n",
       "      <td>-10.269 (+/- 0.324)</td>\n",
       "      <td>-8.211 (+/- 0.405)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape_scorer</th>\n",
       "      <td>-14.539 (+/- 0.449)</td>\n",
       "      <td>-8.405 (+/- 0.096)</td>\n",
       "      <td>-9.918 (+/- 0.234)</td>\n",
       "      <td>-3.071 (+/- 0.035)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Ridge                 SVR  \\\n",
       "fit_time                             0.023 (+/- 0.004)   1.073 (+/- 0.064)   \n",
       "score_time                           0.005 (+/- 0.001)   0.350 (+/- 0.007)   \n",
       "test_neg_mean_squared_error         -1.093 (+/- 0.097)  -0.503 (+/- 0.018)   \n",
       "train_neg_mean_squared_error        -1.071 (+/- 0.048)  -0.427 (+/- 0.013)   \n",
       "test_neg_root_mean_squared_error    -1.044 (+/- 0.047)  -0.709 (+/- 0.013)   \n",
       "train_neg_root_mean_squared_error   -1.035 (+/- 0.023)  -0.654 (+/- 0.010)   \n",
       "test_neg_mean_absolute_error        -0.806 (+/- 0.025)  -0.531 (+/- 0.009)   \n",
       "train_neg_mean_absolute_error       -0.802 (+/- 0.022)  -0.474 (+/- 0.004)   \n",
       "test_r2                             -0.436 (+/- 0.141)   0.339 (+/- 0.019)   \n",
       "train_r2                            -0.405 (+/- 0.063)   0.440 (+/- 0.016)   \n",
       "test_mape_scorer                   -14.606 (+/- 0.662)  -9.431 (+/- 0.282)   \n",
       "train_mape_scorer                  -14.539 (+/- 0.449)  -8.405 (+/- 0.096)   \n",
       "\n",
       "                                             OneVsRest       Random Forest  \n",
       "fit_time                             0.143 (+/- 0.009)   1.616 (+/- 0.016)  \n",
       "score_time                           0.005 (+/- 0.000)   0.021 (+/- 0.000)  \n",
       "test_neg_mean_squared_error         -0.880 (+/- 0.072)  -0.402 (+/- 0.030)  \n",
       "train_neg_mean_squared_error        -0.835 (+/- 0.046)  -0.057 (+/- 0.001)  \n",
       "test_neg_root_mean_squared_error    -0.938 (+/- 0.039)  -0.634 (+/- 0.024)  \n",
       "train_neg_root_mean_squared_error   -0.913 (+/- 0.025)  -0.239 (+/- 0.003)  \n",
       "test_neg_mean_absolute_error        -0.590 (+/- 0.017)  -0.457 (+/- 0.015)  \n",
       "train_neg_mean_absolute_error       -0.571 (+/- 0.013)  -0.170 (+/- 0.001)  \n",
       "test_r2                             -0.154 (+/- 0.091)   0.473 (+/- 0.027)  \n",
       "train_r2                            -0.095 (+/- 0.061)   0.925 (+/- 0.002)  \n",
       "test_mape_scorer                   -10.269 (+/- 0.324)  -8.211 (+/- 0.405)  \n",
       "train_mape_scorer                   -9.918 (+/- 0.234)  -3.071 (+/- 0.035)  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comb={}\n",
    "for keys in models.keys():\n",
    "    pipe_comb = make_imb_pipeline(RandomOverSampler(sampling_strategy=\"minority\"), preprocessor, models[keys])\n",
    "    results_comb[keys]=mean_std_cross_val_scores(\n",
    "        pipe_comb, X_train, y_train, return_train_score=True, scoring=score_types_reg\n",
    "    )\n",
    "pd.DataFrame(results_comb)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9519454a-f95a-404f-94b6-c619c2273849",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f30622a-0747-4dae-b8e2-f376f8b6c3f0",
   "metadata": {},
   "source": [
    "After comparing different regression models by using various matrix, we found the best model is Random Forest, because we got highest cross-validation score. However, we figured out that we may encounter some overfitting issue with Random Forest model as the difference between train score and validation score is quite wide. So, we further conduct feature selections and hyper-parameter optimization as follows. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "813897a4-22de-4c3c-9c08-b8dcc03e91cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09fdca02-1215-47f1-a028-6324cf4f71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(RandomForestRegressor(random_state=123), n_features_to_select=10)\n",
    "\n",
    "pipe_rf_rfe = make_imb_pipeline(RandomOverSampler(sampling_strategy=\"minority\"), preprocessor, rfe, RandomForestRegressor(random_state=123))\n",
    "\n",
    "results_comb['Random Forest_rfe'] = mean_std_cross_val_scores(pipe_rf_rfe, X_train, y_train, return_train_score=True, scoring=score_types_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac373d52-ae9f-440c-925f-66da7d0df55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVR</th>\n",
       "      <th>OneVsRest</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest_rfe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.023 (+/- 0.004)</td>\n",
       "      <td>1.073 (+/- 0.064)</td>\n",
       "      <td>0.143 (+/- 0.009)</td>\n",
       "      <td>1.616 (+/- 0.016)</td>\n",
       "      <td>6.043 (+/- 0.045)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.350 (+/- 0.007)</td>\n",
       "      <td>0.005 (+/- 0.000)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <td>-1.093 (+/- 0.097)</td>\n",
       "      <td>-0.503 (+/- 0.018)</td>\n",
       "      <td>-0.880 (+/- 0.072)</td>\n",
       "      <td>-0.402 (+/- 0.030)</td>\n",
       "      <td>-0.403 (+/- 0.030)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <td>-1.071 (+/- 0.048)</td>\n",
       "      <td>-0.427 (+/- 0.013)</td>\n",
       "      <td>-0.835 (+/- 0.046)</td>\n",
       "      <td>-0.057 (+/- 0.001)</td>\n",
       "      <td>-0.057 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <td>-1.044 (+/- 0.047)</td>\n",
       "      <td>-0.709 (+/- 0.013)</td>\n",
       "      <td>-0.938 (+/- 0.039)</td>\n",
       "      <td>-0.634 (+/- 0.024)</td>\n",
       "      <td>-0.634 (+/- 0.024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <td>-1.035 (+/- 0.023)</td>\n",
       "      <td>-0.654 (+/- 0.010)</td>\n",
       "      <td>-0.913 (+/- 0.025)</td>\n",
       "      <td>-0.239 (+/- 0.003)</td>\n",
       "      <td>-0.239 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <td>-0.806 (+/- 0.025)</td>\n",
       "      <td>-0.531 (+/- 0.009)</td>\n",
       "      <td>-0.590 (+/- 0.017)</td>\n",
       "      <td>-0.457 (+/- 0.015)</td>\n",
       "      <td>-0.457 (+/- 0.015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <td>-0.802 (+/- 0.022)</td>\n",
       "      <td>-0.474 (+/- 0.004)</td>\n",
       "      <td>-0.571 (+/- 0.013)</td>\n",
       "      <td>-0.170 (+/- 0.001)</td>\n",
       "      <td>-0.170 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-0.436 (+/- 0.141)</td>\n",
       "      <td>0.339 (+/- 0.019)</td>\n",
       "      <td>-0.154 (+/- 0.091)</td>\n",
       "      <td>0.473 (+/- 0.027)</td>\n",
       "      <td>0.472 (+/- 0.029)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>-0.405 (+/- 0.063)</td>\n",
       "      <td>0.440 (+/- 0.016)</td>\n",
       "      <td>-0.095 (+/- 0.061)</td>\n",
       "      <td>0.925 (+/- 0.002)</td>\n",
       "      <td>0.925 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <td>-14.606 (+/- 0.662)</td>\n",
       "      <td>-9.431 (+/- 0.282)</td>\n",
       "      <td>-10.269 (+/- 0.324)</td>\n",
       "      <td>-8.211 (+/- 0.405)</td>\n",
       "      <td>-8.220 (+/- 0.417)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape_scorer</th>\n",
       "      <td>-14.539 (+/- 0.449)</td>\n",
       "      <td>-8.405 (+/- 0.096)</td>\n",
       "      <td>-9.918 (+/- 0.234)</td>\n",
       "      <td>-3.071 (+/- 0.035)</td>\n",
       "      <td>-3.074 (+/- 0.032)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Ridge                 SVR  \\\n",
       "fit_time                             0.023 (+/- 0.004)   1.073 (+/- 0.064)   \n",
       "score_time                           0.005 (+/- 0.001)   0.350 (+/- 0.007)   \n",
       "test_neg_mean_squared_error         -1.093 (+/- 0.097)  -0.503 (+/- 0.018)   \n",
       "train_neg_mean_squared_error        -1.071 (+/- 0.048)  -0.427 (+/- 0.013)   \n",
       "test_neg_root_mean_squared_error    -1.044 (+/- 0.047)  -0.709 (+/- 0.013)   \n",
       "train_neg_root_mean_squared_error   -1.035 (+/- 0.023)  -0.654 (+/- 0.010)   \n",
       "test_neg_mean_absolute_error        -0.806 (+/- 0.025)  -0.531 (+/- 0.009)   \n",
       "train_neg_mean_absolute_error       -0.802 (+/- 0.022)  -0.474 (+/- 0.004)   \n",
       "test_r2                             -0.436 (+/- 0.141)   0.339 (+/- 0.019)   \n",
       "train_r2                            -0.405 (+/- 0.063)   0.440 (+/- 0.016)   \n",
       "test_mape_scorer                   -14.606 (+/- 0.662)  -9.431 (+/- 0.282)   \n",
       "train_mape_scorer                  -14.539 (+/- 0.449)  -8.405 (+/- 0.096)   \n",
       "\n",
       "                                             OneVsRest       Random Forest  \\\n",
       "fit_time                             0.143 (+/- 0.009)   1.616 (+/- 0.016)   \n",
       "score_time                           0.005 (+/- 0.000)   0.021 (+/- 0.000)   \n",
       "test_neg_mean_squared_error         -0.880 (+/- 0.072)  -0.402 (+/- 0.030)   \n",
       "train_neg_mean_squared_error        -0.835 (+/- 0.046)  -0.057 (+/- 0.001)   \n",
       "test_neg_root_mean_squared_error    -0.938 (+/- 0.039)  -0.634 (+/- 0.024)   \n",
       "train_neg_root_mean_squared_error   -0.913 (+/- 0.025)  -0.239 (+/- 0.003)   \n",
       "test_neg_mean_absolute_error        -0.590 (+/- 0.017)  -0.457 (+/- 0.015)   \n",
       "train_neg_mean_absolute_error       -0.571 (+/- 0.013)  -0.170 (+/- 0.001)   \n",
       "test_r2                             -0.154 (+/- 0.091)   0.473 (+/- 0.027)   \n",
       "train_r2                            -0.095 (+/- 0.061)   0.925 (+/- 0.002)   \n",
       "test_mape_scorer                   -10.269 (+/- 0.324)  -8.211 (+/- 0.405)   \n",
       "train_mape_scorer                   -9.918 (+/- 0.234)  -3.071 (+/- 0.035)   \n",
       "\n",
       "                                    Random Forest_rfe  \n",
       "fit_time                            6.043 (+/- 0.045)  \n",
       "score_time                          0.021 (+/- 0.000)  \n",
       "test_neg_mean_squared_error        -0.403 (+/- 0.030)  \n",
       "train_neg_mean_squared_error       -0.057 (+/- 0.001)  \n",
       "test_neg_root_mean_squared_error   -0.634 (+/- 0.024)  \n",
       "train_neg_root_mean_squared_error  -0.239 (+/- 0.003)  \n",
       "test_neg_mean_absolute_error       -0.457 (+/- 0.015)  \n",
       "train_neg_mean_absolute_error      -0.170 (+/- 0.001)  \n",
       "test_r2                             0.472 (+/- 0.029)  \n",
       "train_r2                            0.925 (+/- 0.002)  \n",
       "test_mape_scorer                   -8.220 (+/- 0.417)  \n",
       "train_mape_scorer                  -3.074 (+/- 0.032)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbe8c2ed-b53f-4710-8fc7-746b3e12870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf_rfe.fit(X_train, y_train)\n",
    "pipe_rf_rfe.named_steps['rfe'].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb7b5f81-74c5-4793-93b8-9fe504bcaea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_fs = pipe_rf_rfe.named_steps[\"rfe\"].support_\n",
    "rfe_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6aab20c2-fd6e-4033-a8b1-a8a3542e7476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'pH',\n",
       "       'sulphates', 'alcohol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_selected_feats = X_train.columns[rfe_fs]\n",
    "rfe_selected_feats"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccc79d99-faa3-403e-8eda-d6874b185625",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16b36144-6af4-4e6b-927d-7cd8d5b6c410",
   "metadata": {},
   "source": [
    "By using Recursive Feature Elimination algorithm, we chose to drop \"type\" and \"density\" features. Because by dropping those two features, even though we did not get much better scores, we are able to achieve the same scores with lesser features. It is great because it will simplify our model and save cost for future data collection. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "15d0cad3-6106-4bbb-87d1-730537e69fa7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5fe175e-979f-4932-93fc-a3e942e65dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "779abf58-612c-46e0-a7ec-5cc4a432784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('randomoversampler',\n",
       "                                              RandomOverSampler(sampling_strategy='minority')),\n",
       "                                             ('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                               Pipeline(steps=[('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['fixed '\n",
       "                                                                                'acidity',\n",
       "                                                                                'volatile '\n",
       "                                                                                'acidity',\n",
       "                                                                                'citric '\n",
       "                                                                                'acid',\n",
       "                                                                                'residual '\n",
       "                                                                                'sugar',\n",
       "                                                                                'chlorides',\n",
       "                                                                                'free '\n",
       "                                                                                'sulfur '\n",
       "                                                                                'dioxide',\n",
       "                                                                                't...\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'randomforestregressor__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1806c2bc0>,\n",
       "                                        'randomforestregressor__max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1804c1b40>,\n",
       "                                        'randomforestregressor__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1806c0280>},\n",
       "                   random_state=123)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\"randomforestregressor__max_depth\": randint(low=5, high=1000),\n",
    "             \"randomforestregressor__max_leaf_nodes\": randint(low=5, high=1000),\n",
    "             \"randomforestregressor__n_estimators\": randint(low=5, high=1000),}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_rf_rfe,\n",
    "    param_distributions=param_dist,\n",
    "    n_jobs=-1,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45a838e1-2783-42ba-a4c5-eae87901d26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__max_depth': 344,\n",
       " 'randomforestregressor__max_leaf_nodes': 851,\n",
       " 'randomforestregressor__n_estimators': 258}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "430b5140-9453-436c-8b97-29a00767afd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4756738804987327"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6143d201-a408-4537-a790-b9fca63e35d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087659489993155"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0f258a0-0e1c-4269-b09e-2a0f86dc93af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5225714417802303"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09784e37-f0b0-494b-bf0b-d7042bd9aa55",
   "metadata": {},
   "source": [
    "|  | Scores |\n",
    "| -----------: | --------------: |\n",
    "|          Best Cross-validation Score |         0.475673    |\n",
    "|          Best Train Score |            0.908765 |\n",
    "|          Best Test Score  |             0.522571 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33820343-78bb-4332-9a62-7d297b44cdf3",
   "metadata": {},
   "source": [
    "Finally, we conduct hyper-parameter optimization. We employed random search to look for same key hyper-parameters, such as max_depth, max_leaf_nodes, and n_estimators. The best hyper-parameter value we got from the algorithm are ['max_depth': 344, 'max_leaf_nodes': 851, 'n_estimators': 258]. And the best validation score we got is 0.48. And the test score is 0.52 after tunning the hyper-parameters. However, as we discovered above, the train score is 0.91, which means we still have overfitting issue by using Random Forest model. We may investigate further and figure out the next steps later. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c32186f3-ac63-4979-ba9d-fd9cd477072a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42dd103-ed65-49b3-986b-3e06aac02c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wine]",
   "language": "python",
   "name": "conda-env-wine-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
